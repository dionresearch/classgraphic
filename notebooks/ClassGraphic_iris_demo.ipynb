{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9289fb",
   "metadata": {},
   "source": [
    "# Classgraphic Iris (multiclass) demo\n",
    "\n",
    "For demos, classgraphic has a convenience module, `essential`. This way you can start right away with an `import *`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6894f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classgraphic.essential import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f569a0c3",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "max_iter = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6575600",
   "metadata": {},
   "source": [
    "## Data wrangling\n",
    "\n",
    "We will load the data for the Iris data set from plotly express, already available as px (thanks to `classgraphic.essential`). We'll describe the dataframe and visually check if there are any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "df = px.data.iris()\n",
    "\n",
    "# let's see what kind of data we have\n",
    "describe(df, transpose=True).show()\n",
    "\n",
    "# any missing?\n",
    "missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8358278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making one value NaN on purpose\n",
    "df.iloc[2,2] = np.nan\n",
    "\n",
    "# any missing now?\n",
    "missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636fc59",
   "metadata": {},
   "source": [
    "Given the warning above, and seeing there is only one row affected, we will drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fad005",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a8b9a",
   "metadata": {},
   "source": [
    "## Building a model\n",
    "\n",
    "We are now ready to assign our X (features) and y (our target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = df.drop(columns=[\"species\", \"species_id\"])\n",
    "\n",
    "#target\n",
    "y = df[\"species\"]\n",
    "\n",
    "# Let's check our classes we will be training on and predicting\n",
    "class_imbalance_table(y, condition=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f40b50a",
   "metadata": {},
   "source": [
    "The classes are well balanced, even as we removed one observation. Our train and test split will have a lot more impact on the class imbalance, especially as we will not specify `stratify=y`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b535219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=random_state\n",
    ")\n",
    "\n",
    "# we want to see total count for each, default for bars is to be stacked, so that works\n",
    "# we could also pass to class_imbalance barmode=\"overlay\" if we prefer\n",
    "class_imbalance(y_train, y_test, condition=\"train,test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33074c11",
   "metadata": {},
   "source": [
    "We are now ready to train our model, a straightforward LogisticRegression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = LogisticRegression(max_iter=max_iter, random_state=random_state)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_score = model.predict_proba(X_test)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89211d5f",
   "metadata": {},
   "source": [
    "## Evaluating the model performance\n",
    "\n",
    "We will start with a confusion matrix. This also will give us MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331edf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_table(model, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88025ca0",
   "metadata": {},
   "source": [
    "We can also look at several metrics, per classes and at macro and weighted averages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_table(model, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2df43d",
   "metadata": {},
   "source": [
    "Let's have a look at the actual results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f09090",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_table(model, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a1882e",
   "metadata": {},
   "source": [
    "We can also look at the coefficients by classes or by features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94645a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance(model, y).show()\n",
    "feature_importance(model, y, transpose=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5162187f",
   "metadata": {},
   "source": [
    "Let's have a look at what the features looked like for the first 10 predictions (adjustable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, data = view(X_test, y_test, y_pred, extended=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35ea93b",
   "metadata": {},
   "source": [
    "And we can visualize our class errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352fd679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_error(model, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e650b471",
   "metadata": {},
   "source": [
    "Other useful diagnostic plots include Precision/Recall, threshold (FPR, TPR) and ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f665611",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall(model, y_test, y_score).show()\n",
    "threshold(model, y_test, y_score).show()\n",
    "roc(model, y_test, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d99d22",
   "metadata": {},
   "source": [
    "## Looking at probabilities\n",
    "\n",
    "With linear classification models, we usually have a good spread, unlike some other models where we get something either 0 or near zero, or 1 or near one. In our case here, we can visualize the probabilities by predicted or real classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdcfea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_histogram(model, y_test, y_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
