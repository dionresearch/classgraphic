{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7703cc7c",
   "metadata": {},
   "source": [
    "# ClassGraphic binary classification demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d999489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classgraphic.essential import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5f40a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e474ee",
   "metadata": {},
   "source": [
    "Let's create a demo dataset for binary classification, where the outcome of an experiment is true (1) or false (0). We will generate 500 observations with 5 features, or measurements. For this demo, we'll make the classes biased to the true (1) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bfe056",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=500, n_features=5, weights=[0.23, 0.77], random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bdb0a4",
   "metadata": {},
   "source": [
    "What does the data look like? `describe` will give us statistics, and `missing` will show us if there are any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c494f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1fff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6476d",
   "metadata": {},
   "source": [
    "Now on the `target` side of things, let's see how many true and false values we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_imbalance(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa159cde",
   "metadata": {},
   "source": [
    "We have on purpose set the positive or true class to be a tad over 3/4 of the samples. Normally we do not know that in advance, so the pie chart helps us to visualize this.\n",
    "\n",
    "Next step is to do a split of our data into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a2e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e7b29",
   "metadata": {},
   "source": [
    "We have a pretty large test_size (half), but still, let's look at how train and test compare as far as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135daf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_imbalance(y_train, y_test, condition=\"train,test\", sort=True, reference=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70bc328",
   "metadata": {},
   "source": [
    "That's the default. For easier comparison of two sets, in this case the bar chart might be easier to evaluate. We can either have them displayed as \"stack\" (default) bars, or as \"overlay\" (or \"group\" or \"relative\"). Options are there depending on your preference..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df1a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_imbalance(y_train, y_test, condition=\"train,test\", sort=True, always_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_imbalance(y_train, y_test, condition=\"train,test\", sort=True, always_bar=True, barmode=\"overlay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c926e46",
   "metadata": {},
   "source": [
    "Any way we look at this, the difference for our True class between train and test is not exagerated, 16 observations. A similar 16 observations difference for our False (0) class however is a much bigger portion. It would be preferable in this scenario to stratify our split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107958e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.5, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a08494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_imbalance(y_train, y_test, condition=\"train,test\", sort=True, always_bar=True, barmode=\"overlay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5240494",
   "metadata": {},
   "source": [
    "Train and test are now matching. But there is still a large imbalance between our True and False observation. We will keep that in mind, but will move forward.\n",
    "\n",
    "Let's now train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ccaa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(max_iter=200, random_state=random_state)\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5d417b",
   "metadata": {},
   "source": [
    "Let's now get direct predictions and prediction probabilites from our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e28d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = lr_model.predict_proba(X_test)\n",
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f4faaf",
   "metadata": {},
   "source": [
    "It is important to visualize the class errors. This can be done with bar charts or with a confusion matrix, or both. When using two visualizations in a single cell, the first one has to have .show(), else it will not be displayed in the notebook result cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_error(lr_model, y_test, y_pred).show()\n",
    "confusion_matrix_table(lr_model, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc9ff6",
   "metadata": {},
   "source": [
    "We can also get more metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acacf15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_table(lr_model, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f5dda",
   "metadata": {},
   "source": [
    "Overall, not doing bad, but our Negative class predictions are not as good as for our True or Positive class. Would it improve if we instructed LogisticRegression to balance the class weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(max_iter=200, random_state=random_state, class_weight=\"balanced\")\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf15477",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = lr_model.predict_proba(X_test)\n",
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f586917",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_error(lr_model, y_test, y_pred).show()\n",
    "confusion_matrix_table(lr_model, y_test, y_pred).show()\n",
    "classification_table(lr_model, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec78c49",
   "metadata": {},
   "source": [
    "We are doing better on the recall for our negative class, but the precision went down.\n",
    "\n",
    "Let's look at the Precision Recall and ROC plots for this \"balanced\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c218c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "precision_recall(lr_model, y_test, y_pred).show()\n",
    "roc(lr_model, y_test, y_probs[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f917b4a8",
   "metadata": {},
   "source": [
    "Finally, let's look at the feature importance and the probability histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62efc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance(lr_model, y).show()\n",
    "prediction_histogram(lr_model, y_test, y_pred, nbins=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
